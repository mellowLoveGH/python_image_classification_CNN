{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras01.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JDeDVc-TGyc"
      },
      "source": [
        "import keras \n",
        "from keras.datasets import mnist \n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, Dropout \n",
        "from keras.optimizers import RMSprop \n",
        "import numpy as np "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tx2TBYG4YOUR"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data() \n",
        "x_train = x_train.reshape(60000, 784) \n",
        "x_test = x_test.reshape(10000, 784) \n",
        "x_train = x_train.astype('float32') \n",
        "x_test = x_test.astype('float32') \n",
        "x_train /= 255 \n",
        "x_test /= 255 \n",
        "\n",
        "print(len(x_train))\n",
        "print(x_train[:5])\n",
        "print(len(x_test))\n",
        "print(x_test[:5])\n",
        "print()\n",
        "print(len(y_train))\n",
        "print(y_train[:5])\n",
        "print(len(y_test))\n",
        "print(y_test[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGWb5yIiYtFC"
      },
      "source": [
        "y_train = keras.utils.to_categorical(y_train, 10) \n",
        "y_test = keras.utils.to_categorical(y_test, 10) \n",
        "print(len(y_train))\n",
        "print(y_train[:5])\n",
        "print(len(y_test))\n",
        "print(y_test[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rS6yQpVY3k3"
      },
      "source": [
        "model = Sequential() \n",
        "model.add(Dense(512, activation='relu', input_shape = (784,))) \n",
        "model.add(Dropout(0.2)) \n",
        "model.add(Dense(512, activation = 'relu')) \n",
        "model.add(Dropout(0.2)) \n",
        "model.add(Dense(10, activation = 'softmax'))\n",
        "model.compile(loss = 'categorical_crossentropy', \n",
        "   optimizer = RMSprop(), \n",
        "   metrics = ['accuracy']) \n",
        "history = model.fit(x_train, y_train, \n",
        "   batch_size = 128, epochs = 20, verbose = 1, validation_data = (x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISCqrWYjZWVH"
      },
      "source": [
        "pred = model.predict(x_test)\n",
        "print(pred[0])\n",
        "print(y_test[0])\n",
        "print()\n",
        "pred = np.argmax(pred, axis = 1)\n",
        "label = np.argmax(y_test,axis = 1) \n",
        "print(pred) \n",
        "print(label)\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "acc = accuracy_score(label, pred)\n",
        "print(acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iQieTm3xQQL"
      },
      "source": [
        "import keras \n",
        "from keras.datasets import mnist \n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, Dropout, Flatten \n",
        "from keras.layers import Conv2D, MaxPooling2D \n",
        "from keras import backend as K \n",
        "import numpy as np\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "img_rows, img_cols = 28, 28 \n",
        "\n",
        "if K.image_data_format() == 'channels_first': \n",
        "   x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols) \n",
        "   x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols) \n",
        "   input_shape = (1, img_rows, img_cols) \n",
        "else: \n",
        "   x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1) \n",
        "   x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1) \n",
        "   input_shape = (img_rows, img_cols, 1) \n",
        "   \n",
        "x_train = x_train.astype('float32') \n",
        "x_test = x_test.astype('float32') \n",
        "x_train /= 255 \n",
        "x_test /= 255 \n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, 10) \n",
        "y_test = keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "model = Sequential() \n",
        "model.add(Conv2D(32, kernel_size = (3, 3),  \n",
        "   activation = 'relu', input_shape = input_shape)) \n",
        "model.add(Conv2D(64, (3, 3), activation = 'relu')) \n",
        "model.add(MaxPooling2D(pool_size = (2, 2))) \n",
        "model.add(Dropout(0.25)) \n",
        "model.add(Flatten()) \n",
        "model.add(Dense(128, activation = 'relu')) \n",
        "model.add(Dropout(0.5)) \n",
        "model.add(Dense(10, activation = 'softmax'))\n",
        "\n",
        "model.compile(loss = keras.losses.categorical_crossentropy, \n",
        "   optimizer = keras.optimizers.Adadelta(), metrics = ['accuracy'])\n",
        "\n",
        "model.fit(\n",
        "   x_train, y_train, \n",
        "   batch_size = 128, \n",
        "   epochs = 12, \n",
        "   verbose = 1, \n",
        "   validation_data = (x_test, y_test)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dHFX1cvyvAC",
        "outputId": "4e49d2f1-5655-4944-e35d-53780ab0443c"
      },
      "source": [
        "score = model.evaluate(x_test, y_test, verbose = 0) \n",
        "\n",
        "print('Test loss:', score[0]) \n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.7631145119667053\n",
            "Test accuracy: 0.8373000025749207\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjTRmZ71u1X0"
      },
      "source": [
        "import cv2\n",
        "\n",
        "path = 'test.png'\n",
        "#path = 'test.png'\n",
        "img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "img = cv2.resize(img, (28, 28) )\n",
        "print(img.shape)\n",
        "print()\n",
        "img = 1 - img / 255\n",
        "#print(img)\n",
        "img = img.reshape(1, 28, 28, 1)\n",
        "print(x_test[0].shape)\n",
        "print(y_test[0].shape)\n",
        "pt = model.predict(img)\n",
        "pt = np.argmax(pt, axis = 1)\n",
        "\n",
        "print(pt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_tZQJd-K-Bi",
        "outputId": "8ffc66ec-d770-4c95-a949-7588904d0ffe"
      },
      "source": [
        "# RNN LSTM\n",
        "from keras.preprocessing import sequence \n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, Embedding \n",
        "from keras.layers import LSTM \n",
        "from keras.datasets import imdb\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words = 2000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWRHU4oLLFdi",
        "outputId": "a177d177-6ee1-4d74-fc25-58d10c95bd41"
      },
      "source": [
        "print(len(x_train))\n",
        "print(len(x_test))\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=80) \n",
        "x_test = sequence.pad_sequences(x_test, maxlen=80)\n",
        "\n",
        "model = Sequential() \n",
        "model.add(Embedding(2000, 128)) \n",
        "model.add(LSTM(128, dropout = 0.2, recurrent_dropout = 0.2)) \n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "model.compile(loss = 'binary_crossentropy', \n",
        "   optimizer = 'adam', metrics = ['accuracy'])\n",
        "model.fit(\n",
        "   x_train, y_train, \n",
        "   batch_size = 32, \n",
        "   epochs = 15, \n",
        "   validation_data = (x_test, y_test)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000\n",
            "25000\n",
            "(25000, 80)\n",
            "(25000, 80)\n",
            "Epoch 1/15\n",
            "782/782 [==============================] - 209s 264ms/step - loss: 0.5239 - accuracy: 0.7233 - val_loss: 0.3747 - val_accuracy: 0.8283\n",
            "Epoch 2/15\n",
            "782/782 [==============================] - 207s 265ms/step - loss: 0.3563 - accuracy: 0.8455 - val_loss: 0.3934 - val_accuracy: 0.8166\n",
            "Epoch 3/15\n",
            "782/782 [==============================] - 208s 265ms/step - loss: 0.3084 - accuracy: 0.8713 - val_loss: 0.3673 - val_accuracy: 0.8349\n",
            "Epoch 4/15\n",
            "782/782 [==============================] - 208s 266ms/step - loss: 0.2758 - accuracy: 0.8836 - val_loss: 0.3831 - val_accuracy: 0.8374\n",
            "Epoch 5/15\n",
            "782/782 [==============================] - 207s 265ms/step - loss: 0.2507 - accuracy: 0.8950 - val_loss: 0.3978 - val_accuracy: 0.8372\n",
            "Epoch 6/15\n",
            "782/782 [==============================] - 207s 265ms/step - loss: 0.2263 - accuracy: 0.9081 - val_loss: 0.4272 - val_accuracy: 0.8345\n",
            "Epoch 7/15\n",
            "782/782 [==============================] - 207s 265ms/step - loss: 0.1952 - accuracy: 0.9241 - val_loss: 0.4056 - val_accuracy: 0.8339\n",
            "Epoch 8/15\n",
            "782/782 [==============================] - 207s 265ms/step - loss: 0.1774 - accuracy: 0.9328 - val_loss: 0.4423 - val_accuracy: 0.8190\n",
            "Epoch 9/15\n",
            "782/782 [==============================] - 207s 264ms/step - loss: 0.1591 - accuracy: 0.9388 - val_loss: 0.5227 - val_accuracy: 0.8188\n",
            "Epoch 10/15\n",
            "782/782 [==============================] - 206s 264ms/step - loss: 0.1648 - accuracy: 0.9376 - val_loss: 0.5492 - val_accuracy: 0.8286\n",
            "Epoch 11/15\n",
            "782/782 [==============================] - 207s 264ms/step - loss: 0.1267 - accuracy: 0.9531 - val_loss: 0.5761 - val_accuracy: 0.8260\n",
            "Epoch 12/15\n",
            "782/782 [==============================] - 207s 265ms/step - loss: 0.1093 - accuracy: 0.9599 - val_loss: 0.6530 - val_accuracy: 0.8252\n",
            "Epoch 13/15\n",
            "782/782 [==============================] - 207s 265ms/step - loss: 0.0961 - accuracy: 0.9643 - val_loss: 0.6653 - val_accuracy: 0.8219\n",
            "Epoch 14/15\n",
            "782/782 [==============================] - 207s 265ms/step - loss: 0.0919 - accuracy: 0.9677 - val_loss: 0.6568 - val_accuracy: 0.8206\n",
            "Epoch 15/15\n",
            "782/782 [==============================] - 207s 265ms/step - loss: 0.0825 - accuracy: 0.9704 - val_loss: 0.6767 - val_accuracy: 0.8153\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f491a24cc18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmYXpSIwLj3v"
      },
      "source": [
        "score, acc = model.evaluate(x_test, y_test, batch_size = 32) \n",
        "   \n",
        "print('Test score:', score) \n",
        "print('Test accuracy:', acc)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}